{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import itertools as itt\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Governing_Council',\n",
       " 'decided',\n",
       " 'to',\n",
       " 'raise',\n",
       " 'the',\n",
       " 'three',\n",
       " 'key',\n",
       " 'ECB',\n",
       " 'interest_rates',\n",
       " 'by',\n",
       " '75',\n",
       " 'basis_points',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenisation\n",
    "\n",
    "text = \"The Governing Council decided to raise the three key ECB interest rates by 75 basis points.\"\n",
    "\n",
    "bigrams = [\"Governing Council\", \"interest rates\", \"basis points\"]\n",
    "\n",
    "for bigram in bigrams:\n",
    "    text = text.replace(bigram, bigram.replace (\" \", \"_\"))\n",
    "bigrams = [bigram.replace(\" \", \"_\") for bigram in bigrams]\n",
    "\n",
    "tkns = nltk.word_tokenize(text)\n",
    "tkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'governing_council',\n",
       " 'decided',\n",
       " 'to',\n",
       " 'raise',\n",
       " 'the',\n",
       " 'three',\n",
       " 'key',\n",
       " 'ecb',\n",
       " 'interest_rates',\n",
       " 'by',\n",
       " '75',\n",
       " 'basis_points',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift to lower case:\n",
    "[word.lower() for word in tkns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'governing_council',\n",
       " 'decided',\n",
       " 'to',\n",
       " 'raise',\n",
       " 'the',\n",
       " 'three',\n",
       " 'key',\n",
       " 'ecb',\n",
       " 'interest_rates',\n",
       " 'by',\n",
       " '75',\n",
       " 'basis_points']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkns = [word.lower() for word in tkns if word not in string.punctuation]\n",
    "tkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['governing_council',\n",
       " 'decided',\n",
       " 'raise',\n",
       " 'three',\n",
       " 'key',\n",
       " 'ecb',\n",
       " 'interest_rates',\n",
       " '75',\n",
       " 'basis_points']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkns = [word for word in tkns if word not in nltk.corpus.stopwords.words(\"english\")]\n",
    "tkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['governing_council',\n",
       " 'decid',\n",
       " 'rais',\n",
       " 'three',\n",
       " 'key',\n",
       " 'ecb',\n",
       " 'interest_rates',\n",
       " '75',\n",
       " 'basis_points']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "tkns = [stemmer.stem(word) if word not in bigrams else word for word in tkns]\n",
    "tkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create document feature matrix\n",
    "\n",
    "texts = [\n",
    "    \"The Governing Council decided to raise the three key ECB interest rates by 75 basis points. Following the raising of the deposit facility rate to above zero, the two-tier system for the remuneration of excess reserves is no longer necessary.\",\n",
    "    \"The Governing Council decided to raise the three key ECB interest rates by 50 basis points. At the Governing Council’s upcoming meetings, further normalisation of interest rates will be appropriate. The Governing Council’s future policy rate path will continue to be data-dependent and will help to deliver on its 2% inflation target over the medium term\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['governing_council',\n",
       " 'decid',\n",
       " 'rais',\n",
       " 'three',\n",
       " 'key',\n",
       " 'ecb',\n",
       " 'interest_rates',\n",
       " '75',\n",
       " 'basis_points']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to do our pre-processing steps:\n",
    "\n",
    "def pre_process_text(text, bigrams):\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "\n",
    "    for bigram in bigrams:\n",
    "        text = text.replace(bigram, bigram.replace (\" \", \"_\"))\n",
    "    bigrams = [bigram.replace(\" \", \"_\") for bigram in bigrams]\n",
    "\n",
    "    tkns = [word.lower() for word in nltk.word_tokenize(text) if word not in string.punctuation]\n",
    "    tkns = [word for word in tkns if word not in nltk.corpus.stopwords.words(\"english\")]\n",
    "    tkns = [stemmer.stem(word) if word not in bigrams else word for word in tkns]\n",
    "    return tkns\n",
    "\n",
    "\n",
    "\n",
    "pre_process_text(text, [\"Governing Council\", \"interest rates\", \"basis points\"])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['governing_council',\n",
       "  'decid',\n",
       "  'rais',\n",
       "  'three',\n",
       "  'key',\n",
       "  'ecb',\n",
       "  'interest_rates',\n",
       "  '75',\n",
       "  'basis_points',\n",
       "  'follow',\n",
       "  'rais',\n",
       "  'the_deposit_facil',\n",
       "  'rate',\n",
       "  'zero',\n",
       "  'two-tier',\n",
       "  'system',\n",
       "  'remuner',\n",
       "  'of_excess_reserv',\n",
       "  'longer',\n",
       "  'necessari'],\n",
       " ['governing_council',\n",
       "  'decid',\n",
       "  'rais',\n",
       "  'three',\n",
       "  'key',\n",
       "  'ecb',\n",
       "  'interest_rates',\n",
       "  '50',\n",
       "  'basis_points',\n",
       "  'governing_council',\n",
       "  'upcom',\n",
       "  'meet',\n",
       "  'normalis',\n",
       "  'interest_rates',\n",
       "  'appropri',\n",
       "  'governing_council',\n",
       "  'future_policy_r',\n",
       "  'path',\n",
       "  'continu',\n",
       "  'data-depend',\n",
       "  'help',\n",
       "  'deliv',\n",
       "  '2',\n",
       "  '_inflation_target',\n",
       "  'medium',\n",
       "  'term']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use the following bigrams:\n",
    "\n",
    "bigrams = [\"Governing Council\", \"interest rates\", \"basis points\", \" deposit facility\", \" excess reserves\", \" policy rate\", \" inflation target\"]\n",
    "\n",
    "# We also have to replace \"Governing Council's\" with Governing Council (because the latter is a bigram):\n",
    "texts = [text.replace (\"Governing Council’s\", \" Governing Council\") for text in texts]\n",
    "\n",
    "# Pre-process\n",
    "tkns = [pre_process_text(text, bigrams) for text in texts]\n",
    "tkns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0,\n",
       "        1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 3, 1, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique tokens and count\n",
    "all_tkns = set(list(itt.chain.from_iterable(tkns)))\n",
    "\n",
    "X = np.array([[tkn.count(t) for t in all_tkns] for tkn in tkns])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.69314718, 0.69314718, 0.        , 0.        ,\n",
       "        0.69314718, 0.        , 0.69314718, 0.69314718, 0.        ,\n",
       "        0.        , 0.        , 0.69314718, 0.        , 0.69314718,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.69314718, 0.        , 0.69314718, 0.        , 0.        ,\n",
       "        0.        , 0.69314718, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.69314718, 0.69314718,\n",
       "        0.        , 0.69314718, 0.        , 0.        , 0.69314718,\n",
       "        0.69314718, 0.69314718, 0.        , 0.        , 0.        ,\n",
       "        0.69314718, 0.69314718, 0.69314718, 0.        , 0.        ,\n",
       "        0.        , 0.69314718, 0.        , 0.69314718, 0.69314718,\n",
       "        0.69314718, 0.        , 0.        , 0.        , 0.69314718,\n",
       "        0.        , 0.        , 0.69314718]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = np.log(X.shape[0]) - np.array([np.log(np.sum(x > 0)) for x in X.T]) # iterate over columns\n",
    "Xstar = X.copy().astype(float)\n",
    "for (j, w) in enumerate(tfidf):\n",
    "    Xstar[:, j] *= w\n",
    "Xstar\n",
    "\n",
    "# In practice, we don't do this by hand each time -- there are functions in e.g. scikit learn that can construct tfidf matrices for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43876345447627835   0.0\n"
     ]
    }
   ],
   "source": [
    "# Similarity metrics\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "print(cosine_similarity(X[0,:], X[1, :]), \" \", cosine_similarity(Xstar[0,:], Xstar[1, :]))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embeddings\n",
    "# nltk.download('word2vec_sample')\n",
    "word2vec_sample = str(nltk.data.find(\"models/word2vec_sample/pruned.word2vec.txt\"))\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model[\"university\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.04623e-02, -4.63157e-02,  6.78263e-02,  1.14723e-01,\n",
       "        1.06972e-01, -3.41069e-02,  6.74387e-02, -4.88349e-02,\n",
       "       -1.23541e-02, -7.44151e-02,  4.84473e-02, -5.15480e-02,\n",
       "        1.26932e-02,  3.08125e-02, -8.64301e-02,  4.38448e-03,\n",
       "       -8.33294e-02, -3.04249e-02,  7.44151e-02, -5.30983e-02,\n",
       "       -3.10063e-03,  6.78263e-02,  1.91851e-02, -1.34441e-03,\n",
       "        1.92578e-03, -8.52673e-02, -5.89120e-02,  1.26932e-02,\n",
       "       -4.68970e-02,  2.67429e-02,  5.27107e-02, -3.54635e-02,\n",
       "       -2.28671e-02, -2.25765e-02,  3.21690e-02, -8.29419e-02,\n",
       "        2.30609e-02,  3.72076e-02, -2.53864e-02,  5.73617e-02,\n",
       "       -3.93392e-02,  2.06386e-02, -3.27504e-02,  1.53094e-02,\n",
       "       -2.51926e-02, -3.99206e-02,  1.24025e-02, -4.57343e-02,\n",
       "       -1.08522e-01,  1.27780e-03,  3.87579e-02, -7.79033e-02,\n",
       "        6.82139e-02,  2.55802e-02,  9.37941e-02,  1.09491e-02,\n",
       "       -1.08522e-01,  2.37392e-03,  2.83417e-03, -4.74784e-02,\n",
       "       -7.90661e-02, -5.27107e-02,  2.36423e-02, -2.82932e-02,\n",
       "       -2.26734e-02,  4.14225e-03,  8.81742e-03,  2.15106e-02,\n",
       "        3.05218e-03,  3.97268e-03, -1.68984e-01,  8.68176e-02,\n",
       "        6.82139e-02, -1.20925e-01, -4.41840e-02,  8.13915e-02,\n",
       "       -1.91851e-02,  3.72076e-02,  2.33516e-02,  2.30609e-02,\n",
       "       -8.18760e-03, -2.40299e-02,  3.00374e-02,  4.39902e-02,\n",
       "       -5.27107e-02, -3.39131e-02, -5.19356e-02,  7.01518e-02,\n",
       "       -3.02311e-02,  7.05393e-02, -7.05393e-02, -1.00770e-01,\n",
       "       -6.47257e-02, -8.33294e-02,  4.68970e-02,  3.48821e-03,\n",
       "        6.08499e-02,  2.01541e-02,  1.06100e-02, -7.13145e-02,\n",
       "       -4.68970e-02, -5.58113e-02, -8.91431e-02, -3.77889e-02,\n",
       "        1.79255e-02,  1.36622e-02, -7.48027e-02, -1.28385e-03,\n",
       "        8.87555e-02, -1.51156e-01, -1.27901e-01,  4.24399e-02,\n",
       "        1.09297e-01,  8.29419e-02,  6.47257e-02, -2.13168e-02,\n",
       "       -1.90883e-02, -8.48797e-02,  5.03852e-02,  1.43404e-01,\n",
       "       -8.21667e-02, -4.45716e-02,  3.35256e-02,  1.37590e-02,\n",
       "       -9.72823e-02, -8.25543e-02,  5.58113e-02, -1.85069e-02,\n",
       "        4.12771e-02, -2.00572e-02,  7.82909e-02, -1.51156e-02,\n",
       "       -6.43381e-02, -1.28870e-02,  4.14709e-02, -6.20126e-02,\n",
       "        2.71305e-02,  5.07728e-02, -6.27878e-02, -1.91851e-02,\n",
       "       -1.11623e-01, -8.02288e-02,  2.53864e-02,  7.01518e-02,\n",
       "       -2.71305e-03,  9.57320e-02,  3.62386e-02,  4.78660e-02,\n",
       "        1.67628e-02,  3.91455e-02,  1.04646e-01,  1.49218e-02,\n",
       "       -4.90287e-02,  3.60448e-02,  4.30212e-02, -4.24399e-02,\n",
       "        7.63530e-02, -6.62760e-02,  5.38734e-02,  9.38667e-04,\n",
       "        5.76523e-03,  2.84870e-02,  1.31777e-01,  5.46486e-02,\n",
       "        4.49591e-02, -4.96585e-04,  7.48027e-02,  2.56771e-03,\n",
       "       -2.84870e-02, -3.70138e-02,  2.01541e-02,  2.80995e-02,\n",
       "       -2.80995e-02, -3.75951e-02,  1.41466e-02,  5.59567e-03,\n",
       "        4.99977e-02,  4.67032e-02,  1.47280e-02,  7.94536e-02,\n",
       "       -1.67628e-02,  2.53864e-02, -2.33516e-02, -6.74387e-02,\n",
       "        2.75181e-02,  1.86038e-02, -3.95330e-02,  4.94163e-02,\n",
       "        9.92202e-02,  2.69367e-02,  2.65491e-02,  3.12485e-03,\n",
       "       -3.97268e-02,  7.24772e-02, -1.60458e-01, -9.83481e-03,\n",
       "        5.11604e-02, -2.04448e-02, -8.91431e-03,  1.85311e-03,\n",
       "       -5.58113e-02,  4.36026e-02,  7.36400e-02, -3.43007e-02,\n",
       "       -3.51243e-03, -5.03852e-02,  1.11623e-01, -1.12398e-01,\n",
       "       -3.85641e-02, -3.53666e-03,  1.05421e-01,  1.40043e-04,\n",
       "        1.03096e-01, -6.27878e-02, -1.17049e-01,  9.45692e-02,\n",
       "       -8.41046e-02,  5.77492e-02, -4.65094e-02,  1.03193e-02,\n",
       "       -7.17021e-02, -5.89120e-02,  1.81193e-02,  5.01430e-03,\n",
       "        1.18599e-01,  5.69741e-02,  5.91058e-03,  5.23231e-02,\n",
       "        7.17021e-03, -6.12859e-03,  7.17021e-02,  5.96871e-02,\n",
       "       -2.46112e-02,  2.10746e-03,  3.89517e-02, -8.64301e-02,\n",
       "        1.00770e-01,  1.09975e-02, -6.78263e-02,  5.23231e-02,\n",
       "        5.30983e-02, -4.99977e-02, -5.11604e-02, -2.45870e-03,\n",
       "       -1.80224e-02, -7.13145e-02, -6.97642e-02, -8.62363e-03,\n",
       "       -5.58113e-02,  2.66460e-04,  3.24597e-03,  5.65865e-02,\n",
       "        6.16250e-02,  7.67406e-02, -2.61616e-02, -8.79804e-02,\n",
       "       -7.60623e-03,  5.38734e-02, -4.59281e-02,  1.29839e-02,\n",
       "        7.28648e-02,  2.18982e-02, -8.72052e-02,  3.72076e-02,\n",
       "        4.96101e-02,  1.58907e-02, -5.59567e-03, -1.03871e-01,\n",
       "       -2.29640e-02, -2.71305e-02,  5.61989e-02, -7.28648e-02,\n",
       "        1.23056e-02,  1.71504e-02, -8.62363e-03, -6.78263e-02,\n",
       "        2.30609e-02, -1.12398e-01, -2.63554e-02, -6.78263e-03,\n",
       "       -1.70535e-02, -6.78263e-02,  8.17791e-02,  4.88349e-02,\n",
       "        4.59281e-02,  4.82536e-02,  3.66262e-02,  2.24796e-02,\n",
       "        7.67406e-02,  1.41466e-02, -6.24002e-02,  7.12176e-03,\n",
       "       -1.51156e-01,  4.68970e-02,  8.33294e-02,  1.33715e-02,\n",
       "       -2.77119e-02,  3.35256e-02,  3.75467e-03,  2.94560e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"university\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('universities', 0.7003918290138245),\n",
       " ('faculty', 0.6780906915664673),\n",
       " ('undergraduate', 0.6587095856666565),\n",
       " ('campus', 0.6434988379478455),\n",
       " ('college', 0.638526976108551)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"university\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Norway', 0.7291736602783203)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive = [\"Oslo\", \"Germany\"], negative = [\"Berlin\"], topn = 1) # Germany − Berlin + Oslo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72917366"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(model[\"Germany\"] - model[\"Berlin\"] + model[\"Oslo\"], model[\"Norway\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Queen', 0.4929390251636505)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive = [\"King\", \"Woman\"], negative = [\"Man\"], topn = 1) # King − Man + Woman"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asadt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
